\documentclass{article}

\usepackage[]{float,latexsym,times}
\usepackage{amsfonts,amstext,amsmath,amssymb,amsthm}
\usepackage{mathrsfs}
\usepackage{bbm}
\usepackage[margin=2.5cm]{geometry}
\usepackage{hyperref}
%\usepackage{mnsymbol} % For llangle, rrangle.

\newcommand{\ignore}[1]{}

\renewcommand{\Pr}{\mathbf{P}} % probability measure
\newcommand{\T}{T} % generic stopping time

\newcommand{\prob}[2][]{\Pr_{#1} \left( #2 \right)} % probability measure
\newcommand{\scbeta}[1]{\DBeta_{\left(0, #1\right)}} % probability measure
\DeclareMathOperator{\erf}{\mathrm{Erf}} % error function
\DeclareMathOperator{\erfc}{\mathrm{Erfc}} % complementary error function


%\newcommand{\prob}[1]{{\sf #1}}
%\renewcommand{\Pr}{{\sf P}}           % Probability P.
%\newcommand{\Pro}{{\sf P}}            % Probability P.
\DeclareMathOperator{\EV}{{\sf E}}    % Expected value.
\DeclareMathOperator{\Var}{{\sf Var}} % Variance.
\DeclareMathOperator{\Cov}{{\sf Cov}} % Covariance.
\DeclareMathOperator{\SE}{{\sf SE}}   % Standard error.
\DeclareMathOperator{\diag}{diag}     % Diagonal.


%\DeclareMathOperator{\EV}{\mathbf{E}} % expected value
%\DeclareMathOperator{\Var}{\mathbf{Var}} % variance
%\DeclareMathOperator{\Cov}{\mathbf{Cov}} % covariance
%\DeclareMathOperator{\Corr}{\mathbf{Corr}} % correlation
%\DeclareMathOperator{\SD}{\mathbf{s.d.}} % standard deviation

\DeclareMathOperator{\KLI}{I}
\DeclareMathOperator{\LLR}{\mathcal{L}} % log-likelihood ratio
\DeclareMathOperator{\LR}{\Lambda} % likelihood ratio
\DeclareMathOperator{\Ker}{\mathcal{K}} % integral kernel

\DeclareMathOperator{\DChiSq}{\chi ^2} % normal distribution
\DeclareMathOperator{\DNorm}{\mathcal{N}} % normal distribution
\DeclareMathOperator{\DLogNorm}{\ln \DNorm } % normal distribution
\DeclareMathOperator{\DExp}{\mathrm{Exp}} % exponential distribution
\DeclareMathOperator{\DPareto}{\mathrm{Pareto}} % exponential distribution
\DeclareMathOperator{\DBeta}{\mathrm{Be}} % exponential distribution

% ~~ Linear Algebra ~~
\newcommand{\dotprod}[3][]{#1\langle #2 ,\, #3 #1\rangle}
\newcommand{\ddotprod}[3][]{#1[ #2 ,\, #3 #1]}
\newcommand{\vone}{\One}
%\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}


\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}

% Styling.
\hypersetup{
    colorlinks=true,%
    bookmarksnumbered=true,%
    bookmarksopen=true,%
    citecolor=blue,%
    urlcolor=blue,%
    unicode=true,           % enable unicode encoded PDF strings
    breaklinks=true         % allow links to break over lines by making
                            % links over multiple lines into PDF
                            % links to the same target
}

\begin{document}


\section{Normal (Gaussian)}

Usually written as $\DNorm \left(\mu , \sigma ^2\right)$, it is parameterized by $\mu $ and $\sigma ^2$. Its density is given by
\begin{align*}
    f(x) &= \frac{1}{\sqrt{2 \pi  \sigma ^2}} e^{-\frac{(x - \mu )^2}{2\sigma ^2}}.
\end{align*}
If $X \sim \DNorm \left(\mu , \sigma ^2\right)$,
\begin{align*}
    \EV (X) = \mu , \qquad
    \Var (X) = \sigma ^2.
\end{align*}

\section{Lognormal}

Since $\LR$ is log-normal, it has known partial moments: if $\LR \sim \DLogNorm \left(\mu _{\Lambda }, \sigma _{\Lambda }\right)$,
\begin{align*}
    \int_a^b t^n \,d\prob{\LR \le t} &= e^{n \mu _{\Lambda } + \frac{1}{2} n^2 \sigma _{\Lambda }^2} \left(\Phi \left[\frac{\mu _{\Lambda } + n \sigma _{\Lambda }^2 - \log a}{\sigma _{\Lambda }}\right] - \Phi \left[\frac{\mu _{\Lambda } + n \sigma _{\Lambda }^2 - \log b}{\sigma _{\Lambda}}\right]\right) \\
        &= \frac{1}{2} e^{n \mu _{\Lambda } + \frac{1}{2} n^2 \sigma _{\Lambda }^2} \left(\erf \left[\frac{\mu _{\Lambda } + n \sigma _{\Lambda }^2 - \log a}{\sigma _{\Lambda } \sqrt{2}}\right] - \erf \left[\frac{\mu _{\Lambda } + n \sigma _{\Lambda }^2 - \log b}{\sigma _{\Lambda } \sqrt{2}}\right]\right).
\end{align*}

\newpage

\section{Exponential}


Consider a hypothesis for shift in mean: $\DExp \left(1 / \mu \right) \longrightarrow \DExp \left(1 / \theta \right)$, i.e.
\begin{align*}
    f_0(x) &= \frac{1}{\mu } e^{-\frac{1}{\mu } x}, \\
    f_1(x) &= \frac{1}{\theta } e^{-\frac{1}{\theta } x}.
\end{align*}
\begin{align*}
    \LR (X) &= \frac{f_1(X)}{f_0(X)} = \frac{\mu }{\theta } e^{\left(\frac{1}{\mu } - \frac{1}{\theta }\right) X}, \qquad
        \LR ^{-1}(t) = \frac{\log (t) - \log \left(\frac{\mu }{\theta }\right)}{\frac{1}{\mu } - \frac{1}{\theta }}, \\
    \LLR (X) &= \log \LR (X) = \log \left(\frac{\mu }{\theta }\right) + \left(\frac{1}{\mu } - \frac{1}{\theta }\right) X, \\
    \KLI &= \EV_{\theta} \LLR (X) = \log \left(\frac{\mu }{\theta }\right) - 1 + \frac{\theta }{\mu }.
\end{align*}

\begin{align*}
    \prob{\LR \le t} &= \prob{\LLR \le \log t} = \prob{\left(\frac{1}{\mu } - \frac{1}{\theta }\right) X \le \log t - \log \left(\frac{\mu }{\theta }\right)}.
\end{align*}
Here we have two cases: $\theta > \mu$ and $\theta < \mu$. In the former case
\begin{align*}
    \prob[\eta]{\LR \le t} &= \prob[\eta]{X \le \frac{\log t - \log \left(\frac{\mu }{\theta }\right)}{\frac{1}{\mu } - \frac{1}{\theta }}} \\
        &= \prob[\eta]{\frac{1}{\eta } X \le \frac{\log t - \log \left(\frac{\mu }{\theta }\right)}{\eta \left(\frac{1}{\mu } - \frac{1}{\theta }\right)}} \\
        &= \begin{cases}
        1 - \left(\frac{\mu / \theta }{t}\right)^{1 / \left(\frac{\eta }{\mu } - \frac{\eta }{\theta }\right)} \quad &\text{if} \quad t \ge \mu / \theta, \\
        0 \quad &\text{otherwise},
        \end{cases}
\intertext{i.e. $\LR \sim \DPareto \left( 1 / \left(\frac{\eta }{\mu } - \frac{\eta }{\theta }\right), \frac{\mu }{\theta } \right)$. In the latter case,}
    \prob[\eta]{\LR \le t} &= 1 - \prob[\eta]{\frac{1}{\eta } X \le \frac{-\log t + \log \left(\frac{\mu }{\theta }\right)}{\eta \left(\frac{1}{\theta } - \frac{1}{\mu }\right)}} \\
        &= \begin{cases}
        \left(\frac{t}{\mu / \theta }\right)^{1 / \left(\frac{\eta }{\theta } - \frac{\eta }{\mu }\right)} \quad &\text{if} \quad 0 < t \le \mu / \theta, \\
        1 \quad &\text{if} \quad t > \mu / \theta , \\
        0 \quad &\text{otherwise}.
        \end{cases}
\intertext{i.e. $\LR$ is a scaled version of Beta distribution with $\beta = 1$: $\LR \sim \scbeta{\mu / \theta} \left( 1 / \left(\frac{\eta }{\theta } - \frac{\eta }{\mu }\right), 1 \right)$.}
\end{align*}
In both cases, it has known partial moments:
\begin{align*}
    \int_a^b t^n \,d\prob{\LR \le t} &= \frac{\alpha _{\Lambda } k_{\Lambda }^{\alpha _{\Lambda }}}{n - \alpha _{\Lambda }} \left(b^{n - \alpha _{\Lambda }} - a^{n - \alpha _{\Lambda }}\right), &\text{if } \LR &\sim \DPareto \left(\alpha _{\Lambda }, k_{\Lambda }\right), \\
    \int_a^b t^n \,d\prob{\LR \le t} &= \frac{\alpha _{\Lambda } k_{\Lambda }^{-\alpha _{\Lambda }}}{n + \alpha _{\Lambda }} \left(b^{n + \alpha _{\Lambda }} - a^{n + \alpha _{\Lambda }}\right), &\text{if } \LR &\sim \scbeta{k_{\Lambda }} \left(\alpha _{\Lambda }, 1\right).
\end{align*}

\newpage

\section{Chi-squared}


Consider a hypothesis for shift in mean: $\DChiSq (m) \longrightarrow \DChiSq (n)$, i.e.
\begin{align*}
    f_0(x) &= \frac{1}{2^{m / 2} \Gamma (m / 2) } x^{\frac{m}{2} - 1} e^{-\frac{x}{2 }}, \\
    f_1(x) &= \frac{1}{2^{n / 2} \Gamma (n / 2) } x^{\frac{n}{2} - 1} e^{-\frac{x}{2 }}.
\end{align*}
\begin{align*}
    \LR (X) &= \frac{f_1(X)}{f_0(X)} = \frac{\Gamma (m / 2)}{\Gamma (n / 2)} \left( \frac{X}{2} \right)^{\frac{n - m}{2}}, \qquad
        \LR ^{-1}(t) = 2 \left( \frac{\Gamma (n / 2)}{\Gamma (m / 2)} \, t \right)^{\frac{2}{n - m}}, \\
    \LLR (X) &= \log \LR (X) = \log \left( \frac{\Gamma (m / 2)}{\Gamma (n / 2)} \right) + \frac{n - m}{2} \log \left( \frac{X}{2} \right), \\
    \KLI &= \EV_{n} \LLR (X) = \log \left( \frac{\Gamma (m / 2)}{\Gamma (n / 2)} \right) + \frac{n - m}{2} \, \psi \left( \frac{n}{2} \right), \quad \psi (z) = \frac{\Gamma ^\prime (z) }{\Gamma (z) }.
\end{align*}

\begin{align*}
    \prob{\LR \le t} &= \prob{\left( \frac{X}{2} \right)^{\frac{n - m}{2}} \le \frac{\Gamma (n / 2)}{\Gamma (m / 2)} t}.
\end{align*}
Here we have two cases: $n > m$ and $n < m$. In the former case
\begin{align*}
    \prob[k]{\LR \le t} &= \prob[k]{X \le 2 \left( \frac{\Gamma (n / 2)}{\Gamma (m / 2)} \, t \right)^{\frac{2}{n - m}}}
\intertext{In the latter case,}
    \prob[k]{\LR \le t} &= 1 - \prob[k]{X \le 2 \left( \frac{\Gamma (n / 2)}{\Gamma (m / 2)} \, t \right)^{\frac{2}{n - m}}}
\end{align*}

\newpage


\end{document}
